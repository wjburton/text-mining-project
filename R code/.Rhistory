assoc <- read.csv('assoc.csv', stringsAsFactors = F)
food_list1 <- read.csv('../data/food_list.csv', stringsAsFactors = F)
food_list2 <- read.csv('../data/michael_term_list.csv', stringsAsFactors = F)
food_list2 <- food_list2[-grep(' ', food_list2)]
food_list <- c(food_list1, food_list2)
food_list <- unlist(unique(food_list))
food_list <- tm::stemDocument(food_list)
temp <- apply(assoc[,11:length(assoc)], 2, clean_text )
temp2 <- apply(temp, 2, function(text){
x <- strsplit(text, split = " ")
x <- lapply(x, function(y) tm::stemDocument(y))
new_text <- sapply(x, function(x) unique(x[x %in% food_list])[1])
return(new_text)
})
write.csv(temp2,'temp2.csv', row.names= F)
library(arules)
groceries = read.transactions("temp2.csv", sep = ",")
summary(groceries)
inspect(groceries[1:5])
itemFrequency(groceries[, 1:3])
itemFrequencyPlot(groceries, support = 0.1)
itemFrequencyPlot(groceries, topN = 20)
image(groceries[1:100])
rules <- apriori(groceries, parameter = list(support = 0.006, confidence = 0.25, minlen = 2))
associations <- inspect(rules)
names(associations)[2] <- 'arrow'
associations %>%
arrange(desc(lift)) -> final
head(final,40)
head(final,40)
write.csv(final, 'association_analysis.csv')
food_list1 <- read.csv('../data/food_list.csv', stringsAsFactors = F)
food_list2 <- read.csv('../data/michael_term_list.csv', stringsAsFactors = F)
food_list2 <- food_list2[-grep(' ', food_list2)]
food_list <- c(food_list1, food_list2)
food_list <- unlist(unique(food_list))
food_list <- tm::stemDocument(food_list)
head(food_list)
tail(food_list)
assoc <- read.csv('assoc.csv', stringsAsFactors = F)
head(assoc)
head(assoc)
names(assoc)
ingreds <- apply(assoc[,11:length(assoc)], 2, clean_text )
ingreds <- apply(ingreds, 2, function(text){
x <- strsplit(text, split = " ")
x <- lapply(x, function(y) tm::stemDocument(y))
new_text <- sapply(x, function(x) unique(x[x %in% food_list])[1])
return(new_text)
})
head(final,20)
head(final,20)
food_list <- read.csv('../data/food_list.csv')$unique.x.
head(food_list)
food_list <- read.csv('../data/food_list.csv')$unique.x.
head(food_list)
df <- read_in_recipe_data()
#Reads in the data needed for analysis
read_in_recipe_data <- function(){
ingredients <- read.csv('../data/all_ingredients.csv', stringsAsFactors = F)
recipes <- read.csv('../data/all_recipes.csv', stringsAsFactors = F)
recipes <- recipes[!duplicated(recipes$recipe_id),]
df <- merge(recipes, ingredients, by = 'recipe_id')
}
# cleans the text within an ingredient
clean_text <- function(ingredients, pred_score = F){
temp <- gsub('\\d',"",ingredients) #remove numbers
temp <- gsub('[[:punct:]]', " ", temp) # remove special characters
temp <- gsub(" *\\b[[:alpha:]]{1}\\b *", " ", temp) #remove single letters
temp <- gsub('\\s+', " ", temp) #remove extra white space
temp <- tolower(temp) #to lowercase
return(temp)
}
# clean only keep terms in the term list
clean_ingredients <- function(ingredients, pred_score = F){
clean_ingreds <- clean_text(ingredients)
#read in the food list and stem the words
food_list <- read.csv('../data/food_list.csv')$unique.x.
food_list <- Corpus(VectorSource(food_list))
food_list <- tm_map(food_list, stemDocument)
food_list <- textreg::convert.tm.to.character(food_list)
#only keep words that appear in the food list
clean_ingreds <- as.character(clean_ingreds)
recipe_corpus <- Corpus(VectorSource(clean_ingreds))
recipe_corpus <- tm_map(recipe_corpus, stemDocument)
clean_ingreds <- textreg::convert.tm.to.character(recipe_corpus)
splt_clean_ingreds <- strsplit(clean_ingreds, split = ' ')
clean_ingreds <- sapply(splt_clean_ingreds, function(x){
x <- x[x %in% food_list]
x <- paste(x, collapse = ' ')
return(x)
})
if(pred_score == T){
clean_ingreds <- clean_ingreds[clean_ingreds != ""]
}
return(clean_ingreds)
}
#Create a corpus of recipes removing stopwords and stemming applied
create_corpus <-function(clean_ingredients){
recipe_corpus <- Corpus(VectorSource(clean_ingredients))
recipe_corpus <- tm_map(recipe_corpus, removeWords, stopwords('english'))
recipe_corpus <- tm_map(recipe_corpus, stemDocument)
return(recipe_corpus)
}
#Create a document term frequency vector
doc_term_freq <- function(recipe_corpus){
tf <- as.matrix(TermDocumentMatrix(recipe_corpus))
tdf <- rowSums(tf)
return(tdf)
}
#calculate tf_idf
calculate_tf_idf <- function(recipe1, recipe2, doc_term_freq, n_docs){
corpus <- Corpus(VectorSource(c(recipe1,recipe2)))
tf <- as.matrix(TermDocumentMatrix(corpus))
doc_freq <- doc_term_freq[names(doc_term_freq) %in% rownames(tf)]
idf <-  log((doc_freq/nrow(df))^-1)
tf_idf <- tf*idf
magnitude <- sqrt(colSums(tf_idf^2))
tf_idf[,1] <- tf_idf[,1]/magnitude[1]
tf_idf[,2] <- tf_idf[,2]/magnitude[2]
return(tf_idf)
}
df <- read_in_recipe_data()
head(df)
df$ingredients <- clean_ingredients(df$ingredients)
library(tm)
library(lsa)
library(ggplot2)
library(tibble)
library(dplyr)
library(topicmodels)
library(arules)
df$ingredients <- clean_ingredients(df$ingredients)
freq <- doc_term_freq(Corpus(VectorSource(df$ingredients)))
n_unique_words <- trimws(gsub('\\d', " ", df$ingredients))
n_unique_words <-  strsplit(n_unique_words, split = ' ')
n_unique_words <- sapply(n_unique_words, function(x) length(unique(x[x != ''])))
df$n_unique_words <- n_unique_words
df$nchar_title <- nchar(df$title)
head(df)
str(df)
df$publisher <- as.factor(df$publisher)
linear_model <- lm(social_rank ~ n_unique_words + publisher, data = train)
samp <- sample(1:nrow(df), nrow(df)*0.6)
train <- df[samp,]
valid <- df[-samp,]
df$publisher <- as.factor(df$publisher)
linear_model <- lm(social_rank ~ n_unique_words + publisher, data = train)
summary(linear_model)
linear_model <- lm(social_rank ~ n_unique_words + I(n_unique_words^2)+ publisher, data = train)
summary(linear_model)
linear_model <- lm(social_rank ~ n_unique_words + publisher, data = train)
summary(linear_model)
df <- read_in_recipe_data()
#needed funcitons
#Reads in the data needed for analysis
read_in_recipe_data <- function(){
ingredients <- read.csv('../data/all_ingredients.csv', stringsAsFactors = F)
recipes <- read.csv('../data/all_recipes.csv', stringsAsFactors = F)
recipes <- recipes[!duplicated(recipes$recipe_id),]
df <- merge(recipes, ingredients, by = 'recipe_id')
}
# cleans the text within an ingredient
clean_text <- function(ingredients, pred_score = F){
temp <- gsub('\\d',"",ingredients) #remove numbers
temp <- gsub('[[:punct:]]', " ", temp) # remove special characters
temp <- gsub(" *\\b[[:alpha:]]{1}\\b *", " ", temp) #remove single letters
temp <- gsub('\\s+', " ", temp) #remove extra white space
temp <- tolower(temp) #to lowercase
return(temp)
}
# clean only keep terms in the term list
clean_ingredients <- function(ingredients, pred_score = F){
clean_ingreds <- clean_text(ingredients)
#read in the food list and stem the words
food_list <- read.csv('../data/food_list.csv')$unique.x.
food_list <- Corpus(VectorSource(food_list))
food_list <- tm_map(food_list, stemDocument)
food_list <- textreg::convert.tm.to.character(food_list)
#only keep words that appear in the food list
clean_ingreds <- as.character(clean_ingreds)
recipe_corpus <- Corpus(VectorSource(clean_ingreds))
recipe_corpus <- tm_map(recipe_corpus, stemDocument)
clean_ingreds <- textreg::convert.tm.to.character(recipe_corpus)
splt_clean_ingreds <- strsplit(clean_ingreds, split = ' ')
clean_ingreds <- sapply(splt_clean_ingreds, function(x){
x <- x[x %in% food_list]
x <- paste(x, collapse = ' ')
return(x)
})
if(pred_score == T){
clean_ingreds <- clean_ingreds[clean_ingreds != ""]
}
return(clean_ingreds)
}
#Create a corpus of recipes removing stopwords and stemming applied
create_corpus <-function(clean_ingredients){
recipe_corpus <- Corpus(VectorSource(clean_ingredients))
recipe_corpus <- tm_map(recipe_corpus, removeWords, stopwords('english'))
recipe_corpus <- tm_map(recipe_corpus, stemDocument)
return(recipe_corpus)
}
#Create a document term frequency vector
doc_term_freq <- function(recipe_corpus){
tf <- as.matrix(TermDocumentMatrix(recipe_corpus))
tdf <- rowSums(tf)
return(tdf)
}
#calculate tf_idf
calculate_tf_idf <- function(recipe1, recipe2, doc_term_freq, n_docs){
corpus <- Corpus(VectorSource(c(recipe1,recipe2)))
tf <- as.matrix(TermDocumentMatrix(corpus))
doc_freq <- doc_term_freq[names(doc_term_freq) %in% rownames(tf)]
idf <-  log((doc_freq/nrow(df))^-1)
tf_idf <- tf*idf
magnitude <- sqrt(colSums(tf_idf^2))
tf_idf[,1] <- tf_idf[,1]/magnitude[1]
tf_idf[,2] <- tf_idf[,2]/magnitude[2]
return(tf_idf)
}
# This was used to generate the food list we are filtering the data on
#Clean ingredients
#remove numbers, single letters, special characters,
# clean_food_list <- function(food_list){
#   food_list <- food_list[,-1]
#   food_col <- unlist(lapply(food_list, function(x){
#     x <- x[x != ""]
#     x <- unlist(strsplit(x, split = " "))
#   }))
#   food_col <- unique(food_col)
# }
#
# food_list1 <- read.csv('food_list1.csv',stringsAsFactors = F, header = F)
# food_list2 <-  read.csv('food_list2.csv',stringsAsFactors = F, header = F)
# food_list3 <-  read.csv('food_list3.csv',stringsAsFactors = F, header = F)
#
# food_list1 <- clean_food_list(food_list1)
# food_list2 <- clean_food_list(food_list2)
# food_list3 <- clean_food_list(food_list3)
# food_list <- unique(c(food_list3, food_list2, food_list1))
# food_list <- data.frame(food_list)
# write.csv(food_list, 'food_list.csv', row.names = F)
df <- read_in_recipe_data()
#Clean the ingredients column
clean_recipes <- clean_ingredients(df$ingredients)
library(tm)
library(lsa)
library(ggplot2)
library(tibble)
library(dplyr)
library(topicmodels)
library(arules)
clean_recipes <- clean_ingredients(df$ingredients)
df <- df[names(clean_recipes),]
#do this temporarily to see results
set.seed(100)
rand_samp <- sample(1:length(clean_recipes), 1000)
clean_recipes <- clean_recipes[rand_samp]
sampled_df <- df[rand_samp,] %>% select(-c(f2f_url, source_url,
image_url, page,
publisher_url))
#Create a text corpus of all the recipe ingredients
recipe_corpus <- create_corpus(clean_recipes)
head(sampled_df)
all_recipes <- paste(clean_recipes, collapse = '')
title_word_freq <- table(unlist(strsplit(all_recipes, split = " ")))
title_word_freq <- title_word_freq[!(names(title_word_freq) %in% c(stopwords(),'amp'))]
title_word_freq <- data.frame(title_word_freq)
names(title_word_freq) <- c('word', 'freq')
title_word_freq <- title_word_freq %>% arrange(desc(freq))
#look at the 30 mot frequent and least frequent items
ggplot(title_word_freq[2:30,], aes(x=reorder(ingredient,freq), y=freq)) +
geom_point(size=5, colour="red") + coord_flip() +
ggtitle("Recipe Popularity of Top 30 Ingredients") +
names(title_word_freq) <- c('ingredient', 'freq')
title_word_freq <- title_word_freq %>% arrange(desc(freq))
#look at the 30 mot frequent and least frequent items
ggplot(title_word_freq[1:30,], aes(x=reorder(ingredient,freq), y=freq)) +
geom_point(size=5, colour="red") + coord_flip() +
ggtitle("Recipe Popularity of Top 30 Ingredients") +
xlab('Ingredient')+
ylab('Frequency')+
ggplot(title_word_freq[1:30,], aes(x=reorder(ingredient,freq), y=freq)) +
ggplot(title_word_freq[1:30,], aes(x=reorder(ingredient,freq), y=freq)) +
geom_point(size=5, colour="red") + coord_flip() +
ggtitle("Recipe Popularity of Top 30 Ingredients") +
xlab('Ingredient')+
ylab('Frequency')+
theme(axis.text.x=element_text(size=13,face="bold", colour="black"),
axis.text.y=element_text(size=13,colour="black",
face="bold"), axis.title.x=element_text(size=14, face="bold"),
axis.title.y=element_text(size=14,face="bold"),
plot.title=element_text(size=24,face="bold"))
#create similarity matrix
temp <- as.matrix(TermDocumentMatrix(recipe_corpus))
similarity_cos <- cosine(temp)
library(arules)
#Start by reading in the food lists, then read in a csv containing recipes.
# we clean the recipes by only keeping words that exist in the food list:
#read in food csv files (contains a list of foods that we'd like to keep for
# the analysis
food_list1 <- read.csv('../data/food_list.csv', stringsAsFactors = F)
food_list2 <- read.csv('../data/michael_term_list.csv', stringsAsFactors = F)
#only keep single words .. The method i'm using only looks for single word matches
food_list2 <- food_list2[-grep(' ', food_list2)]
food_list <- c(food_list1, food_list2)
food_list <- unlist(unique(food_list))
food_list <- tm::stemDocument(food_list)
#read in a file that has each ingredient in a recipe as a different column.
# This will be used as a transactional dataset, but first it needs to be cleaned
# to convert things like '12 chicken breasts' to 'chicken'
assoc <- read.csv('../data/assoc.csv', stringsAsFactors = F)
#select the ingredient columns
ingreds <- apply(assoc[,11:length(assoc)], 2, clean_text )
#needed funcitons
#Reads in the data needed for analysis
read_in_recipe_data <- function(){
ingredients <- read.csv('../data/all_ingredients.csv', stringsAsFactors = F)
recipes <- read.csv('../data/all_recipes.csv', stringsAsFactors = F)
recipes <- recipes[!duplicated(recipes$recipe_id),]
df <- merge(recipes, ingredients, by = 'recipe_id')
}
# clean only keep terms in the term list
clean_ingredients <- function(ingredients, pred_score = F){
clean_ingreds <- clean_text(ingredients)
#read in the food list and stem the words
food_list <- read.csv('../data/food_list.csv')$unique.x.
food_list <- Corpus(VectorSource(food_list))
food_list <- tm_map(food_list, stemDocument)
food_list <- textreg::convert.tm.to.character(food_list)
#only keep words that appear in the food list
clean_ingreds <- as.character(clean_ingreds)
recipe_corpus <- Corpus(VectorSource(clean_ingreds))
recipe_corpus <- tm_map(recipe_corpus, stemDocument)
clean_ingreds <- textreg::convert.tm.to.character(recipe_corpus)
splt_clean_ingreds <- strsplit(clean_ingreds, split = ' ')
clean_ingreds <- sapply(splt_clean_ingreds, function(x){
x <- x[x %in% food_list]
x <- paste(x, collapse = ' ')
return(x)
})
if(pred_score == T){
clean_ingreds <- clean_ingreds[clean_ingreds != ""]
}
return(clean_ingreds)
}
# cleans the text within an ingredient
clean_text <- function(ingredients, pred_score = F){
temp <- gsub('\\d',"",ingredients) #remove numbers
temp <- gsub('[[:punct:]]', " ", temp) # remove special characters
temp <- gsub(" *\\b[[:alpha:]]{1}\\b *", " ", temp) #remove single letters
temp <- gsub('\\s+', " ", temp) #remove extra white space
temp <- tolower(temp) #to lowercase
return(temp)
}
#Create a corpus of recipes removing stopwords and stemming applied
create_corpus <-function(clean_ingredients){
recipe_corpus <- Corpus(VectorSource(clean_ingredients))
recipe_corpus <- tm_map(recipe_corpus, removeWords, stopwords('english'))
recipe_corpus <- tm_map(recipe_corpus, stemDocument)
return(recipe_corpus)
}
# This was used to generate the food list we are filtering the data on
#Clean ingredients
#remove numbers, single letters, special characters,
# clean_food_list <- function(food_list){
#   food_list <- food_list[,-1]
#   food_col <- unlist(lapply(food_list, function(x){
#     x <- x[x != ""]
#     x <- unlist(strsplit(x, split = " "))
#   }))
#   food_col <- unique(food_col)
# }
#
# food_list1 <- read.csv('food_list1.csv',stringsAsFactors = F, header = F)
# food_list2 <-  read.csv('food_list2.csv',stringsAsFactors = F, header = F)
# food_list3 <-  read.csv('food_list3.csv',stringsAsFactors = F, header = F)
#
# food_list1 <- clean_food_list(food_list1)
# food_list2 <- clean_food_list(food_list2)
# food_list3 <- clean_food_list(food_list3)
# food_list <- unique(c(food_list3, food_list2, food_list1))
# food_list <- data.frame(food_list)
# write.csv(food_list, 'food_list.csv', row.names = F)
ingreds <- apply(assoc[,11:length(assoc)], 2, clean_text )
ingreds <- apply(ingreds, 2, function(text){
x <- strsplit(text, split = " ")
x <- lapply(x, function(y) tm::stemDocument(y))
new_text <- sapply(x, function(x) unique(x[x %in% food_list])[1])
return(new_text)
})
write.csv(ingreds,'ingred_transactions.csv', row.names= F)
#read in ingred_transactions
ingredients <- read.transactions("ingred_transactions.csv", sep = ",")
#calculate lift support and confidence on the transactional dataset
rules <- apriori(ingredients, parameter = list(support = 0.006, confidence = 0.25, minlen = 2))
#inspect rules extracts the association rules
associations <- inspect(rules)
#this just adds a name to the one of the columns that didn't have a name
names(associations)[2] <- 'arrow'
#arrange the associations by lift
associations %>%
arrange(desc(lift)) -> final
head(final,20)
library(dplyr)
names(associations)[2] <- 'arrow'
#arrange the associations by lift
associations %>%
arrange(desc(lift)) -> final
head(final,20)
all_recipes <- read.csv('../data/all_recipes.csv', stringsAsFactors = F)
df <- df[!duplicated(df$title),]
all_recipes <- all_recips[!duplicated(all_recipes$title),]
all_recipes <- all_recipes[!duplicated(all_recipes$title),]
#Clean the ingredients column
clean_titles <- clean_text(df$title)
clean_titles <- clean_text(all_recipes$title)
all_titles <- paste(clean_titles, collapse = '')
title_word_freq <- table(unlist(strsplit(all_titles, split = " ")))
title_word_freq <- title_word_freq[!(names(title_word_freq) %in% c(stopwords(),'amp'))]
library(tm)
title_word_freq <- title_word_freq[!(names(title_word_freq) %in% c(stopwords(),'amp'))]
title_word_freq <- data.frame(title_word_freq)
names(title_word_freq) <- c('word', 'freq')
title_word_freq <- title_word_freq %>% arrange(desc(freq))
ggplot(title_word_freq[1:30,], aes(x=reorder(word,freq), y=freq)) +
geom_point(size=5, colour="red") + coord_flip() +
ggtitle("Recipe Popularity of Top 30 Ingredients") +
xlab('Ingredient')+
ylab('Frequency')+
theme(axis.text.x=element_text(size=13,face="bold", colour="black"),
axis.text.y=element_text(size=13,colour="black",
face="bold"), axis.title.x=element_text(size=14, face="bold"),
axis.title.y=element_text(size=14,face="bold"),
plot.title=element_text(size=24,face="bold"))
library(ggplot2)
ggplot(title_word_freq[1:30,], aes(x=reorder(word,freq), y=freq)) +
geom_point(size=5, colour="red") + coord_flip() +
ggtitle("Recipe Popularity of Top 30 Ingredients") +
xlab('Ingredient')+
ylab('Frequency')+
theme(axis.text.x=element_text(size=13,face="bold", colour="black"),
axis.text.y=element_text(size=13,colour="black",
face="bold"), axis.title.x=element_text(size=14, face="bold"),
axis.title.y=element_text(size=14,face="bold"),
plot.title=element_text(size=24,face="bold"))
titles <- strsplit(clean_titles, split = ' ')
chicken <- sapply(titles, function(x) 'chicken' %in% x)
chocolate <- sapply(titles, function(x) 'chocolate' %in% x)
sweet <- sapply(titles, function(x) 'sweet' %in% x)
ggtitle("Top 30 Recipe Title Word Counts") +
xlab('Ingredient')+
ylab('Frequency')+
theme(axis.text.x=element_text(size=13,face="bold", colour="black"),
axis.text.y=element_text(size=13,colour="black",
face="bold"), axis.title.x=element_text(size=14, face="bold"),
axis.title.y=element_text(size=14,face="bold"),
plot.title=element_text(size=24,face="bold"))
ggplot(title_word_freq[1:30,], aes(x=reorder(word,freq), y=freq)) +
geom_point(size=5, colour="red") + coord_flip() +
ggtitle("Top 30 Recipe Title Word Counts") +
xlab('Ingredient')+
ylab('Frequency')+
theme(axis.text.x=element_text(size=13,face="bold", colour="black"),
axis.text.y=element_text(size=13,colour="black",
face="bold"), axis.title.x=element_text(size=14, face="bold"),
axis.title.y=element_text(size=14,face="bold"),
plot.title=element_text(size=24,face="bold"))
titles <- strsplit(clean_titles, split = ' ')
chicken <- sapply(titles, function(x) 'chicken' %in% x)
chocolate <- sapply(titles, function(x) 'chocolate' %in% x)
sweet <- sapply(titles, function(x) 'sweet' %in% x)
bacon <- sapply(titles, function(x) 'bacon' %in% x)
cheese <- sapply(titles, function(x) 'cheese' %in% x)
df$chicken <- chicken
df$chocolate <- chocolate
all_recipes$chicken <- chicken
all_recipes$chocolate <- chocolate
all_recipes$sweet <- sweet
all_recipes$bacon <- bacon
all_recipes$cheese <- cheese
temp <- as.matrix(TermDocumentMatrix(recipe_corpus))
mean(all_recipes$social_rank[all_recipes$chicken == 1])
mean(all_recipes$social_rank[all_recipes$chicken == 0])
mean(all_recipes$social_rank[all_recipes$cheese == 1])
mean(all_recipes$social_rank[all_recipes$cheese == 0])
mean(all_recipes$social_rank[all_recipes$cheese == 0])
mean(all_recipes$social_rank[all_recipes$chicken == 1])
mean(all_recipes$social_rank[all_recipes$chicken == 0])
mean(all_recipes$social_rank[all_recipes$chocolate == 1])
mean(all_recipes$social_rank[all_recipes$chocolate == 0])
mean(all_recipes$social_rank[all_recipes$sweet == 1])
mean(all_recipes$social_rank[all_recipes$sweet == 0])
mean(all_recipes$social_rank[all_recipes$bacon == 1])
mean(all_recipes$social_rank[all_recipes$bacon == 0])
mean(all_recipes$social_rank[all_recipes$cheese == 1])
mean(all_recipes$social_rank[all_recipes$cheese == 0])
df <- read_in_recipe_data()
df$ingredients <- clean_ingredients(df$ingredients)
#Variable creation  :We are only creating the number of unique words
n_unique_words <- trimws(gsub('\\d', " ", df$ingredients))
n_unique_words <-  strsplit(n_unique_words, split = ' ')
n_unique_words <- sapply(n_unique_words, function(x) length(unique(x[x != ''])))
df$n_unique_words <- n_unique_words
df$nchar_title <- nchar(df$title)
#we were going to add the cluster a recipe is in.. but they were not significant
samp <- sample(1:nrow(df), nrow(df)*0.6)
train <- df[samp,]
valid <- df[-samp,]
df$publisher <- as.factor(df$publisher)
linear_model <- lm(social_rank ~ n_unique_words + publisher, data = train)
summary(linear_model)
